# CareerNetwork ML Service

Service d'intelligence artificielle pour les recommandations d'emploi bas√© sur SentenceTransformers.

## üöÄ Installation

### 1. Installer les d√©pendances Python

```bash
pip install -r ml-service/requirements.txt
```

### 2. Configuration Kaggle (pour t√©l√©charger le dataset)

Si vous voulez utiliser le dataset Kaggle, vous devez configurer vos credentials Kaggle:

1. Cr√©ez un compte sur [Kaggle](https://www.kaggle.com/)
2. T√©l√©chargez votre fichier `kaggle.json` depuis Account > API
3. Placez-le dans `~/.kaggle/kaggle.json` (Linux/Mac) ou `C:\Users\<username>\.kaggle\kaggle.json` (Windows)

### 3. Initialiser le mod√®le

#### Option A: Utiliser le dataset Kaggle

```bash
python ml-service/init_model.py
```

Cette commande va:
- T√©l√©charger le dataset depuis Kaggle
- Cr√©er les embeddings pour tous les jobs
- Sauvegarder le mod√®le et les donn√©es

#### Option B: Utiliser vos jobs MongoDB

```bash
# D√©finir l'URI MongoDB
export MONGODB_URI="mongodb://localhost:27017/careernetwork"

# Synchroniser les jobs
python ml-service/sync_mongodb.py
```

Cette commande va:
- R√©cup√©rer tous les jobs actifs depuis MongoDB
- Cr√©er les embeddings
- Sauvegarder les donn√©es

## üèÉ D√©marrer le serveur

### Mode d√©veloppement (avec rechargement automatique)

```bash
uvicorn ml-service.app:app --reload --port 8000
```

### Mode production

```bash
python ml-service/app.py
```

Le serveur sera accessible sur `http://localhost:8000`

## üì° API Endpoints

### Health Check

```bash
GET http://localhost:8000/health
```

### Obtenir des recommandations

```bash
POST http://localhost:8000/api/recommend
Content-Type: application/json

{
  "skills": "Python, Machine Learning, Data Analysis",
  "experience": "6 months internship in data analytics",
  "education": "Bachelor in Computer Science",
  "location": "Bangalore, India",
  "contract_type": "Internship",
  "languages": "English, Hindi",
  "certifications": "AWS, Google Data Analytics"
}
```

### R√©ponse

```json
{
  "recommendations": [
    {
      "job_id": null,
      "job_role": "Data Scientist",
      "company": "Tech Corp",
      "location": "Bangalore, India",
      "skills_description": "Python, ML, Data Analysis",
      "score": 85.42
    }
  ],
  "message": "Found 5 recommendations"
}
```

## üîÑ Synchronisation avec MongoDB

Pour mettre √† jour les recommandations avec les nouveaux jobs de MongoDB:

```bash
python ml-service/sync_mongodb.py
```

Vous pouvez automatiser cela avec un cron job ou une t√¢che planifi√©e.

## üê≥ Docker (Optionnel)

Cr√©er un `Dockerfile`:

```dockerfile
FROM python:3.11-slim

WORKDIR /app

COPY ml-service/requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY ml-service/ .

EXPOSE 8000

CMD ["uvicorn", "app:app", "--host", "0.0.0.0", "--port", "8000"]
```

## üìù Notes

- Le mod√®le `all-MiniLM-L6-v2` sera t√©l√©charg√© automatiquement lors de la premi√®re utilisation
- Les embeddings sont sauvegard√©s dans `data/job_embeddings.npy`
- L'index des jobs est sauvegard√© dans `data/jobs_index.pkl`
- Le mod√®le est sauvegard√© dans `models/all-MiniLM-L6-v2`

## üîß Configuration

Vous pouvez configurer le service via des variables d'environnement (voir `.env.example`):

- `PORT`: Port du serveur (d√©faut: 8000)
- `MODEL_PATH`: Chemin vers le mod√®le (d√©faut: `models/all-MiniLM-L6-v2`)
- `EMBEDDINGS_PATH`: Chemin vers les embeddings (d√©faut: `data/job_embeddings.npy`)
- `INDEX_PATH`: Chemin vers l'index (d√©faut: `data/jobs_index.pkl`)
- `MONGODB_URI`: URI MongoDB pour la synchronisation








